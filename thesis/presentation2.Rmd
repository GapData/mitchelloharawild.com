---
title: "Models for forecasting multiple seasonality"
author: "Mitchell O'Hara-Wild"
date: '04/10/2017 <br><br><br><br> Slides @ <a href="http://mitchelloharawild.com/thesis/">mitchelloharawild.com/thesis/</a>'
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    css: ["default", "libs/custom.css", "libs/animate.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE, cache=TRUE, fig.width = 12)
library(thesis)
library(tidyverse)
library(lubridate)
library(fpp2)
library(fasster)

theme_set(theme_gray(base_size = 23))
```

```{r setup_data}
pedestrian <- read_csv("../data/pedestrian.csv") %>%
  rename(DateTime = Date_Time) %>%
  mutate(DateTime = as.POSIXct(strptime(DateTime, "%d-%b-%Y %H:%M"))) %>% 
  select(-ID) %>% 
  distinct()

add_tsNA <- function(obj){
  na_DateTime <- with(obj, seq(min(DateTime), max(DateTime), by=DateTime %>% as.character() %>% as.POSIXct(tz="UTC") %>% diff %>% median) %>%
    as_tibble())
  return(full_join(obj, na_DateTime %>% rename(DateTime=value) %>% as.data.frame, by="DateTime") %>% arrange(DateTime))
}

is_weekend <- function(DateTime){
  wday(DateTime) %in% c(1, 7)
}

pedestrian_cleaned <- pedestrian %>% 
  split(.$Sensor_Name) %>%
  map(~ .x %>% add_tsNA)

pedestrian_tr <- pedestrian_cleaned %>%
  map(~ .x %>%
        filter(between(DateTime, max(DateTime) - years(3), max(DateTime) - years(1))))

pedestrian_ts <- pedestrian_cleaned %>%
  map(~ .x %>%
        filter(DateTime > max(DateTime) - years(1)))
```


## Background & Motivation

The need for models which can appropriately handle time-series data that contain multiple seasonality patterns is growing.

--

This can be attributed to:

* Increased need for understanding sub-daily patterns

--

* Technological improvements collecting high frequency data

--

* Multiple seasonality is common in societal behaviour at high frequencies

---

## Background & Motivation

Currently there are very few tools capable of handling these types of datasets, and those that can lack the flexibility necessary to include all appropriate model components.

Many of the currently used models have substantial shortcomings in terms of speed, flexibility, and accuracy.

Accordingly, new tools are required to allow fast, flexible and accurate modelling of complex time-series structures.

---
class: inverse, center, bottom

background-image: url(resources/pedestrian.jpeg)
background-size: cover

# Pedestrian counts

---

## Key example: Pedestrian counting

```{r}
ped_reg_plot <- pedestrian %>%
  filter(Sensor_Name == "Southern Cross Station") %>%
  filter(DateTime > as.Date("2017-3-27") & DateTime < as.Date("2017-4-24")) %>% 
  mutate(series = "Hourly counts")
ped_agg_plot <- ped_reg_plot %>%
  group_by(date(DateTime)) %>%
  summarise(Hourly_Counts = sum(Hourly_Counts), DateTime = median(DateTime)) %>%
  mutate(series = "Daily counts")

ggplot() +
  geom_line(aes(x=DateTime, y=Hourly_Counts), data = ped_agg_plot) + 
  geom_line(aes(x=DateTime, y=Hourly_Counts), data = ped_reg_plot) +
  facet_grid(series~., scales="free_y") + 
  ylab("Pedestrians counted") + 
  xlab("Date") +
  ggtitle("Temporal granularity in pedestrian traffic at Southern Cross Station")
```

???

43 sensor locations located around our city, which have been providing hourly counts of pedestrians since 2009 (almost 2 million observations!)

Valuable for **understanding** and forecasting pedestrian traffic is valuable for **urban planning, event management and business development**

Lots of data allows models to be tested at scale.

Holiday effects (Easter, point to graph)


Systems which were previously observed daily, can now be measured hourly, revealing these patterns of multiple seasonality.

The availability of multiple seasonal time series data is growing rapidly as sensors that are capable of recording more data, more often become commonplace. 


Requiring accurate MSTS modelling is essential for understanding and predicting these complex systems

---
## Key example: Pedestrian counting

```{r}
ped_plot <- pedestrian %>%
  filter(Sensor_Name == "Southern Cross Station") %>%
  mutate(workday = ifelse(Day %in% c("Saturday", "Sunday"), "Weekend", "Weekday"),
         TimeOnly = DateTime)
date(ped_plot$TimeOnly) <- Sys.Date() # Condense into single day for overlap

ggplot(ped_plot, aes(x = TimeOnly,
                         y=Hourly_Counts,
                         group=date(DateTime))) +
  geom_line(alpha=0.05) + 
  facet_wrap(~ workday) + 
  ylab("Total pedestrians counted") + 
  xlab("Time") + 
  ggtitle("Seasonality in pedestrian traffic at Sth Cross Stn") + 
  scale_x_datetime(date_labels = "%H %p") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

???

Two types of seasonality are present:
- Daily seasonality
- Hourly seasonality

They interact as the hourly pattern changes depending on if it is a weekday, or weekend.

You can imagine how soon there will be further seasonal patterns to model. If you consider pedestrian traffic at universities, you can expect a large surge in pedestrians between class times, introducing a 3rd seasonal pattern to model.

---
class: inverse, center, top

background-image: url(resources/electricity.jpeg)
background-size: cover

# Electricity demand

---

## Key example: Electricity demand

```{r}
elecdemand_plot <- elecdemand %>%
  as.data.frame %>%
  mutate(DateTime = seq(ymd_hms("2014-01-01 00:00:00", tz="ADST"),
                        by=as.difftime(minutes(30)),
                        length.out = NROW(elecdemand)))

elecdemand_reg_plot <- elecdemand_plot %>%
  filter(month(DateTime) %in% c(9,10)) %>%
  mutate(series = "Hourly demand")
elecdemand_agg_plot <- elecdemand_reg_plot %>%
  group_by(date(DateTime)) %>%
  summarise(Demand = sum(Demand), DateTime = median(DateTime)) %>%
  mutate(series = "Daily demand")

ggplot() +
  geom_line(aes(x=DateTime, y=Demand), data = elecdemand_agg_plot) + 
  geom_line(aes(x=DateTime, y=Demand), data = elecdemand_reg_plot) +
  facet_grid(series~., scales="free_y") + 
  ylab("Electricity demanded (GW)") + 
  xlab("Date") +
  ggtitle("Temporal granularity in electricity demand")
```

???

Half-hourly smart meter electricity demand data from Victoria in 2014

Being able to accurately forecast electricity generation need is beeficial for the **environment**, **costs** and **preventing black-outs**

---

## Key example: Electricity demand

```{r}
elecdemand_plot %>%
  filter(DateTime < ymd("2014-02-01")) %>%
  gather("Series", "Value", Demand, Temperature) %>%
  ggplot(aes(x=DateTime, y=Value, group=Series)) +
  geom_line() +
  facet_grid(Series ~ ., scales = "free_y") + 
  ylab("Electricity demanded (GW)") + 
  xlab("Date") + 
  ggtitle("Electricity demanded and temperature")
```

???

An interesting feature of electricity demand is how strongly it relates with Temperature. 
This illustrates the importance of allowing exogenous regressors in a model for predicting these patterns.

---

# Multiple seasonal models

### The ideal model is:

???

So what makes a good model for forecasting multiple seasonality time series?

--

.center[
## Accurate
]

???

Pretty self explanatory, model accuracy is highly desirable. Doesn't require any further justification :)

--

.center[
## Flexible
]

???

Model specification should be flexible to suit a wide range of data applications. A tuned specification reduces the parameterisation problem.

--

.center[
## Fast
]

???

The model should produce estimates in a reasonable amount of time

--

.center[
## Robust
]

???

The model should not be sensitive to outliers or noise.

---
class: inverse, center, middle

# Regression models

???

I think it's safe to assume a basic understanding of regression models, so:

Response is a linearly dependent on the regressors, which can be time series variables

Multiple seasonality is achieved by adding seasonal dummy variables or splines

---

# Considered regression models

### Three regression models are considered:

--

.center[
## Multiple Linear Regression
]

???

Simplest form, with additive and interacting seasonal dummy variables

--

.center[
## Generalised Additive Models
]

???

Which is a generalisation that does not restrict the response as being normally distributed.
Seasonality implemented additively using interacting splines

--

.center[
## Prophet
]

???

A specification of a GAM model recently open-sourced by a Facebook research team.
Seasonality is approximated using a exponential form Fourier series.

---

## Regression model findings

???

Read from slides

--

.pull-left[## Strengths:
- ### Highly flexible specification
- ### Co-variates (and holidays) easily included
- ### Relatively fast]

--

.pull-right[## Weaknesses:
- ### Doesn't naturally handle serial correlation
- ### Time series components cannot evolve over time]

---
class: inverse, center, middle

# State space models

???

A model where the observed response variable is supplemented by unobserved auxiliary state variables. These state variables summarise the history of the observed, and are used to determine future behaviour of the data

The state variables evolve over time in accordance to a recurrance relationship.

---

# Considered state space models

### Three state space models are considered:

--

.center[
## Double-seasonal Holt-Winters
]

???

Simplest form, adds two seasonal terms to the model which evolve over time

--

.center[
## BATS/TBATS
]

???

BATS is an extension of DSHW which includes a Box-Cox transformation, ARMA errors, and unlimited seasonal terms.
TBATS extends BATS by also reformulating the seasonality with a trigonometric Fourier series.

--

.center[
## Multiple seasonal ARIMA
]

???

Implements multiple seasonality by combining seasonal autoregression.
Unlike DSHW, BATS and TBATS, this can handle coregressors.

---

## State space model findings

???

Read from slides

These are more or less the opposite of the regression models.

--

.pull-left[## Strengths:
- ### Time series components evolve over time
- ### Naturally handles serial correlation]

--

.pull-right[## Weaknesses:
- ### Inflexible model specification
- ### Co-variates (and holidays) are difficult to include
- ### Relatively slow]

---

# Proposed model

### A structural state space model, with:

--

- ### Multiple seasonality capabilities

--

- ### Flexible model specification

--

- ### Multiple sources of error

--

- ### Exogenous regressor support

--

- ### Handling of missing values

---
class: inverse, center, top

# Introducing...

.animated.zoomIn[.huge[
# FASSTER
]]

---
class: inverse, center, top

# Introducing...

.huge[
# FASSTER
]

.animated.slideInUp[
## .green.big[Forecasting] with .green.big[Additive] .green.big[Switching] of
## .green.big[Seasonality], .green.big[Trend] & .green.big[Exogenous] .green.big[Regressors]
]

---

# Switching Structure

FASSTER extends currently used state-space approaches by introducing a switching structure to the underlying states.

--

For each switching group in the model, a set of states are maintained for the measurement equation switch between.

--

A generic measurement equation for a state-space model can be written as:
$$y_t = F_t\theta_t + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$

--

Extending this model to switch between two groups gives:
$$y_t = \mathbf{I}_{t\in G_1}F_t\theta_{t}^{(1)} + \mathbf{I}_{t\in G_2}F_t\theta_{t}^{(2)} + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$

Where the groups $G_1$ and $G_2$  $(G_2$ is the complement of $G_1)$ are defined by a switching rule (say Weekdays and Weekends).

--

In this model, the state equations for both groups follow the same structure, but have different error terms that allow them to behave independently. This is not a necessary constraint for the model.

---

# Application to pedestrian traffic

```{r}
SthCross_fasster_tr <- pedestrian_cleaned$`Southern Cross Station` %>%
  filter(DateTime > ymd("2017-01-30") & DateTime <= ymd("2017-02-20"))
fit <- SthCross_fasster_tr %>%
  fasster(Hourly_Counts ~ is_weekend(DateTime) %S% (poly(1) + trig(24)))

as.tibble(SthCross_fasster_tr) %>%
  ggplot(aes(x=DateTime, y=Hourly_Counts)) + 
  geom_line() + 
  ylab("Pedestrians counted") + 
  ggtitle("Pedestrian Traffic at Southern Cross Station") +
  xlab("Date")
```

Each group in this series contain a daily pattern, which switches between weekdays and weekends.
The series in each group can be modelled using level and seasonal states.
---

# Modelling with FASSTER

The state equations are set to contain a level $(\ell)$ and hourly trigonometric seasonality $(f_{24})$ (where $\ell$ and $f_{24}$ are defined later):

$$F_t\theta_t^{(i)} = \ell_{t}^{(i)} + f_{t}^{(i)}$$

$$y_t = \mathbf{I}_{t\in Weekday}F_t\theta_{t}^{(Weekday)} + \mathbf{I}_{t\in Weekend}F_t\theta_{t}^{(Weekend)} + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$

--

```{r}
as.tibble(SthCross_fasster_tr) %>%
  rename(Actual = Hourly_Counts) %>%
  mutate(Fitted = fit$fitted) %>%
  gather(Series, Values, Actual, Fitted) %>%
  ggplot(aes(x=DateTime, y=Values, colour=Series)) + 
  geom_line() + 
  ylab("Pedestrians counted") + 
  ggtitle("Pedestrian Traffic at Southern Cross Station") +
  xlab("Date")
```

---

## FASSTER allows flexible use of:
- ### seasonal factors
- ### fourier seasonal terms
- ### n-th order polynomials
- ### exogenous regressors
- ### ARMA processes
- ### state switching

???

So lets explore how these underlying states are built.
The equations are standard for DLMs and state-space models, so in the interest of time, these will be glossed over.

---

# seas(m): seasonal factors

This creates seasonal factors with frequency s.

Like other state space models (such as DSHW and BATS), seasonal factors are defined by rotating states.

For identification, the seasonal states set to sum to 0, reducing the required states by 1.

$$s_{1,t} = -\sum_{j=1}^m s_{j,t-1} + w_{1,t}, \hspace{1em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

$$s_{j,t} = s_{j-1, t-1} + w_{j,t}, \hspace{1em} w_{j,t} \sim \mathcal{N}(0,0) \hspace{1em}\forall j = 2, ..., m-1$$

---

# trig(m, q): seasonal fourier terms

This creates seasonal fourier terms with frequency s using q harmonics.
(Where $q \leq \lfloor s/2 \rfloor$)

As defined in TBATS, the underlying states for seasonal fourier terms are:

\begin{align*}
f_t &= \sum_{j=1}^{q} f_{j,t}\\
f_{j,t} &= f_{j,t-1}\cos \lambda_j + f_{j,t-1}^{*}\sin \lambda_j + \gamma_1d_t\\
f_{j,t}^{*} &= -f_{j,t-1}\sin \lambda_j + f_{j,t-1}^{*}\cos \lambda_j + \gamma_2d_t\\
\end{align*}

$$\text{Where }\lambda_j = \dfrac{2\pi j}{m}$$

Trigonometric seasonality is advantageous as it is:

- More flexible
- Reduces parameterisation problem
- Supports non-integer seasonal periods

???

This provides a more flexible specification of seasonality than seasonal factors, and reducing the number of harmonics can help speed up the model (with a trade off of smoother seasonality).

---

# poly(n): n-th order polynomials

This creates levels, trends, and higher order polynomial states

The state equation for a level $(\ell_t)$ in the model (poly(1)) is given by:
$$\ell_t = \ell_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

Extending this to include a trend state $(b_t)$ in the model (poly(2)) makes the state equations:

$$\ell_t = \ell_{t-1} + b_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$
$$b_t = b_{t-1} + w_{2,t}, \hspace{2em} w_{2,t} \sim \mathcal{N}(0,W_2)$$

In general, the $n^{th}$ order polynomial (poly(n)) is built with the states:
$$\theta_{j,t} = \theta_{j,t-1} + \theta_{j+1, t-1} + w_{j,t}, \hspace{1em} w_{j,t} \sim \mathcal{N}(0,W_j), \hspace{1em}\forall j=1,\ldots,n-1$$
$$\theta_{n,t} = \theta_{n,t-1} + w_{n,t}, \hspace{2em} w_{n,t} \sim \mathcal{N}(0,W_n)$$

---

# xreg: Exogenous regressors

Regression terms can be constructed by using a state to represent the regression coefficient for each regressor.
$$\beta_t = \beta_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

Then in the measurement equation, the coefficient for the state $\beta_t$ $(F_t)$ can be defined as the regressor itself $(x_t)$:

$$y_t = \beta_t x_t + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$
This has the benefit of allowing the regressor coefficient to evolve over time.

---

# ARMA(ar, ma): ARMA processes

Adding ARMA processes to state space models is a natural extension to correct remaining correlation structure in the residuals.

For ar $= (\phi_1, \ldots, \phi_p)$ and ma $= (\theta_1, \ldots, \theta_q)$, the appropriate states are given by:

\begin{align*}
\gamma_1,t &= \phi_1 \gamma_{1,t-1} + \gamma_{2, t-1} + \varepsilon_t\\
\gamma_j,t &= \phi_j \gamma_{1,t-1} + \gamma_{j+1, t-1} + \theta_{j-1} \varepsilon_t, & \forall j = 1, \ldots, r-1\\
\gamma_r,t &= \phi_r \gamma_{1,t-1} + \theta_{r-1} \varepsilon_t\\
\end{align*}

Where,
\begin{align*}
r &= max\{p, q+1\}\\
\phi_j &= 0, \hspace{1em}\forall j>r\\
\theta_j &= 0, \hspace{1em}\forall j>r-1\\
\varepsilon_t &\sim \mathcal{N}(0, \sigma^2)
\end{align*}

---

# %S%: State switching

The general measurement equation in a FASSTER model is:

$$y_t = F_t^{(0)}\theta_{t}^{(0)} + \sum_{j=1}^k\mathbf{I}_{t\in G_j}F_t^{(j)}\theta_{t}^{(j)} + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$

--

Note that:
- Each group can be built with a different model of states
- Groups can overlap, allowing complex state switching

--

.center.bold[This greatly enhances the flexibility of the model.]

---
class: inverse, center, top

# Model speed

--

## (It's not called FASSTER for nothing!)

---

# FASSTER and Dynamic Linear Models

A FASSTER model can be represented as a time-varying DLM.
This involves constructing the appropriate $F_t$ matrix to create the switching structure.

\begin{align*}
  y_t &= F_t\theta_t + v_t, & v_t&\sim \mathcal{N}(0,V)\\
  \theta_t &= G\theta_{t-1} + w_t, & w_t&\sim \mathcal{N}(0,W)\\
  \text{Where }\theta_0 &\sim \mathcal{N}(m_0, C_0)
\end{align*}

--

Therefore,

- State estimation can use the Kalman Filter
- Filtering, smoothing and forecasting can be done quickly*.

.footnote[[*] Relative to state-space models]

---

# Curse of dimensionality

Consider the model for pedestrian traffic seen earlier.
\begin{align*}
y_t &= \mathbf{I}_{t\in Weekday}F_t\theta_{t}^{(Weekday)} + \mathbf{I}_{t\in Weekend}F_t\theta_{t}^{(Weekend)} + v_t & v_t &\sim \mathcal{N}(0,V)\\
\end{align*}
$$\text{Where }F_t\theta_t^{(i)} = \ell_{t}^{(i)} + f_{t}^{(i)}$$

This model has 48 state equations (2 groups $\times$ (1 level + 23 fourier states)).

--

<hr>

The components that require estimation (bolded) are:
\begin{align*}
  y_t &= F_t\theta_t + v_t, & v_t&\sim \mathcal{N}(0,\mathbf{V})\\
  \theta_t &= G\theta_{t-1} + w_t, & w_t&\sim \mathcal{N}(0,\mathbf{W})\\
  \text{Where }\theta_0 &\sim \mathcal{N}(\mathbf{m_0}, \mathbf{C_0})
\end{align*}

There are well over 100 parameters that require estimation.

--

.center[Numerical optimisation techniques involving the .bold[MLE is infeasible]!]

???

If the model is built in the state-space framework... doesn't that mean it is slow?

(10 years of hourly data has 87,660 observations).
Computing the likelihood is slow due to the series length.

---

# Heuristic estimation (filterSmooth)

1. Filtering the data using the specified model with non-zero state variances

--

2. Obtain smoothed states $(\theta_t^{(s)} = \theta_t | \mathcal{D}_T)$ to approximate correct behaviour

--

3. The initial state parameters taken from the first smoothed state:
\begin{align*}
m_0 &= \mathbb{E}\left(\theta_0^{(s)}\right), & C_0 &= \text{Var}\left(\theta_0^{(s)}\right)
\end{align*}

--

4. Obtain state noise variances from the smoothed variance of $w_t$:
$$W = \text{Var}\left(w_t^{(s)}\right) = \text{Var}\left(\theta_t^{(s)} - G\theta_{t-1}^{(s)}\right)$$

--

5. Obtain measurement noise variance from smoothed variance of $v_t$:
$$V = \text{Var}\left(v_t^{(s)}\right) = \text{Var}\left(y_t - F_t\theta_t^{(s)}\right)$$

--

6. Repair restricted state variances for seasonal factors and ARMA terms

--

.center.bold[Only two passes through the data are required.]

---

class: inverse, center, top

# Implementation

.animated.zoomIn.sticker-math[
![fasster](resources/fasster.png)
]

---

class: inverse, center, top

# Implementation

.sticker-math[
![fasster](resources/fasster.png)
]

.sticker-math[
![dlm](resources/dlm.png)
![tidyverse](resources/tidyverse.png)
![forecast](resources/forecast.png)
]

???

Special note that since my last presentation, we have made a sticker for the forecast package!

---
class: inverse, top

.sticker-float[![fasster](resources/fasster.png)]
<br>
.center[
# The fasster package for R
]

<br>
<br>

The **development** version can be installed from GitHub using:

```{r, echo = TRUE, eval = FALSE}
# install.packages("devtools")
devtools::install_github("mitchelloharawild/fasster")
```

---

# Usage (Pedestrian Counts)
```{r}
SthCross_Ex <- SthCross_fasster_tr %>%
  mutate(DayType = ifelse(is_weekend(DateTime), "Weekend", "Weekday")) %>%
  select(DateTime, Hourly_Counts, DayType)
```

```{r, echo = TRUE}
SthCross_Ex %>%
  fasster(Hourly_Counts ~ DayType %S% (poly(1) + trig(24))) %>%
  ggfitted
```

---

# Usage (Electricity Demand)

```{r}
elecdemand_Ex <- elecdemand_plot %>%
  filter(DateTime < ymd("2014-02-01"))
```

```{r, echo=TRUE}
elecdemand_Ex %>%
  fasster(Demand ~ I(Temperature - mean(Temperature))^2 + WorkDay %S% (poly(1) + trig(48, 16))) %>% 
  ggfitted
```

---

.sticker-float[![dlm](resources/dlm.png)]
<br>
# Built on top of dlm

The **dlm** package by Giovanni Petris is the backbone for the **fasster** package.

It provides the model's object structure, Kalman filter and Kalman smoother functions.

**fasster** extends the **dlm** package by supporting time-varying forecasts.

---

.sticker-float[![tidyverse](resources/tidyverse.png)]
<br>
# Consistent with tidyverse API

---

.sticker-float[![forecast](resources/forecast.png)]
<br>
# Extends the forecast package

**fasster** models and forecasts are consistent with the forecast object structure

---
class: inverse, center, top

# Applications and results

---

# Extensions

- Automatic detection of groups / model
- More flexible within-group model specification
- Streaming data
- Improved heuristic estimation

---
class: inverse, center, top

# Questions?
