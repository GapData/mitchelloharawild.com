---
title: "Models for forecasting multiple seasonality"
author: "Mitchell O'Hara-Wild"
date: '04/10/2017 <br><br><br><br> Slides @ <a href="http://mitchelloharawild.com/thesis/">mitchelloharawild.com/thesis/</a>'
output:
  xaringan::moon_reader:
    chakra: libs/remark-latest.min.js
    css: ["default", "libs/custom.css", "libs/animate.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE, cache=TRUE, fig.width = 12)
library(thesis)
library(tidyverse)
library(lubridate)
library(fpp2)
library(fasster)
library(knitr)
library(kableExtra)

theme_set(theme_gray(base_size = 23))
```

```{r setup_data}
pedestrian <- read_csv("../data/pedestrian.csv") %>%
  rename(DateTime = Date_Time) %>%
  mutate(DateTime = as.POSIXct(strptime(DateTime, "%d-%b-%Y %H:%M"))) %>% 
  select(-ID) %>% 
  distinct()

add_tsNA <- function(obj){
  na_DateTime <- with(obj, seq(min(DateTime), max(DateTime), by=DateTime %>% as.character() %>% as.POSIXct(tz="UTC") %>% diff %>% median) %>%
    as_tibble())
  return(full_join(obj, na_DateTime %>% rename(DateTime=value) %>% as.data.frame, by="DateTime") %>% arrange(DateTime))
}

is_weekend <- function(DateTime){
  wday(DateTime) %in% c(1, 7)
}

pedestrian_cleaned <- pedestrian %>% 
  split(.$Sensor_Name) %>%
  map(~ .x %>% add_tsNA)

pedestrian_tr <- pedestrian_cleaned %>%
  map(~ .x %>%
        filter(between(DateTime, max(DateTime) - years(3), max(DateTime) - years(1))))

pedestrian_ts <- pedestrian_cleaned %>%
  map(~ .x %>%
        filter(DateTime > max(DateTime) - years(1)))
```


## Background & Motivation

There is a **growing demand** for tools that can handle **multiple seasonality**.

<br>

???

The need for models which can appropriately handle time-series data that contain multiple seasonality patterns is growing.

--

This can be attributed to:

* Increased need for **understanding sub-daily patterns**

* **Technological improvements** collecting high frequency data

* **Multiple seasonality is common** in societal behaviour at high frequencies

--

<br>

**Very few tools are available** that appropriately model these patterns.

Currently used tools have **poor speed, flexibility, or accuracy**.

So, to support modelling of these complex structures, **new tools are needed**.

---
class: inverse, center, bottom

background-image: url(resources/pedestrian.jpeg)
background-size: cover

# Pedestrian counts

---

## Key example: Pedestrian counting

```{r}
ped_reg_plot <- pedestrian %>%
  filter(Sensor_Name == "Southern Cross Station") %>%
  filter(DateTime > as.Date("2017-3-27") & DateTime < as.Date("2017-4-24")) %>% 
  mutate(series = "Hourly counts")
ped_agg_plot <- ped_reg_plot %>%
  group_by(date(DateTime)) %>%
  summarise(Hourly_Counts = sum(Hourly_Counts), DateTime = median(DateTime)) %>%
  mutate(series = "Daily counts")

ggplot() +
  geom_line(aes(x=DateTime, y=Hourly_Counts), data = ped_agg_plot) + 
  geom_line(aes(x=DateTime, y=Hourly_Counts), data = ped_reg_plot) +
  facet_grid(series~., scales="free_y") + 
  ylab("Pedestrians counted") + 
  xlab("Date") +
  ggtitle("Temporal granularity in pedestrian traffic at Sthrn Cross Stn")
```

???

43 sensor locations located around our city, which have been providing hourly counts of pedestrians since 2009 (almost 2 million observations!)

Valuable for **understanding** and forecasting pedestrian traffic is valuable for **urban planning, event management and business development**

Lots of data allows models to be tested at scale.

Holiday effects (Easter, point to graph)


Systems which were previously observed daily, can now be measured hourly, revealing these patterns of multiple seasonality.

The availability of multiple seasonal time series data is growing rapidly as sensors that are capable of recording more data, more often become commonplace. 


Requiring accurate MSTS modelling is essential for understanding and predicting these complex systems

---
## Key example: Pedestrian counting

```{r}
ped_plot <- pedestrian %>%
  filter(Sensor_Name == "Southern Cross Station") %>%
  mutate(workday = ifelse(Day %in% c("Saturday", "Sunday"), "Weekend", "Weekday"),
         TimeOnly = DateTime)
date(ped_plot$TimeOnly) <- Sys.Date() # Condense into single day for overlap

ggplot(ped_plot, aes(x = TimeOnly,
                         y=Hourly_Counts,
                         group=date(DateTime))) +
  geom_line(alpha=0.05) + 
  facet_wrap(~ workday) + 
  ylab("Total pedestrians counted") + 
  xlab("Time") + 
  ggtitle("Seasonality in pedestrian traffic at Southern Cross Station") + 
  scale_x_datetime(date_labels = "%H %p") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

???

Two types of seasonality are present:
- Daily seasonality
- Hourly seasonality

They interact as the hourly pattern changes depending on if it is a weekday, or weekend.

You can imagine how soon there will be further seasonal patterns to model. If you consider pedestrian traffic at universities, you can expect a large surge in pedestrians between class times, introducing a 3rd seasonal pattern to model.

---
class: inverse, center, top

background-image: url(resources/electricity.jpeg)
background-size: cover

# Electricity demand

---

## Key example: Electricity demand

```{r}
elecdemand_plot <- elecdemand %>%
  as.data.frame %>%
  mutate(DateTime = seq(ymd_hms("2014-01-01 00:00:00", tz="ADST"),
                        by=as.difftime(minutes(30)),
                        length.out = NROW(elecdemand)))

elecdemand_reg_plot <- elecdemand_plot %>%
  filter(month(DateTime) %in% c(9,10)) %>%
  mutate(series = "Hourly demand")
elecdemand_agg_plot <- elecdemand_reg_plot %>%
  group_by(date(DateTime)) %>%
  summarise(Demand = sum(Demand), DateTime = median(DateTime)) %>%
  mutate(series = "Daily demand")

ggplot() +
  geom_line(aes(x=DateTime, y=Demand), data = elecdemand_agg_plot) + 
  geom_line(aes(x=DateTime, y=Demand), data = elecdemand_reg_plot) +
  facet_grid(series~., scales="free_y") + 
  ylab("Electricity demanded (GW)") + 
  xlab("Date") +
  ggtitle("Temporal granularity in electricity demand")
```

???

Half-hourly smart meter electricity demand data from Victoria in 2014

Being able to accurately forecast electricity generation need is beeficial for the **environment**, **costs** and **preventing black-outs**

---

## Key example: Electricity demand

```{r}
elecdemand_plot %>%
  filter(DateTime < ymd("2014-02-01")) %>%
  gather("Series", "Value", Demand, Temperature) %>%
  ggplot(aes(x=DateTime, y=Value, group=Series)) +
  geom_line() +
  facet_grid(Series ~ ., scales = "free_y") + 
  ylab("Electricity demanded (GW)") + 
  xlab("Date") + 
  ggtitle("Electricity demanded and temperature")
```

???

An interesting feature of electricity demand is how strongly it relates with Temperature. 
This illustrates the importance of allowing exogenous regressors in a model for predicting these patterns.

---

# Multiple seasonal models

### The ideal model is:

.center[
## Accurate

## Flexible

## Fast
]

???

So what makes a good model for forecasting multiple seasonality time series?

---
class: inverse, center, middle

# Suggested models for 
# multiple seasonality

---

### Regression models

.center[
### Multiple Linear Regression
### Generalised Additive Models
### Prophet
]

???

A specification of a GAM model recently open-sourced by a Facebook research team.
Seasonality is approximated using a Fourier series.

--

### State space models

.center[
### Double-seasonal Holt-Winters
### BATS/TBATS
### Multiple seasonal ARIMA
]


???

A model where the observed response variable is supplemented by unobserved auxiliary state variables. These state variables summarise the history of the observed, and are used to determine future behaviour of the data

The state variables evolve over time in accordance to a recurrance relationship.

---

## Model performance comparison
<table class="table">
  <thead>
    <tr>
      <th>Model</th>
      <th>Flexible</th>
      <th>Speed</th>
      <th>Accuracy</th>
      <th>Exogenous Regressors</th>
      <th>Dynamic Terms</th>
      <th>Evolving Terms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>MLR</td>
      <td class="success">Yes</td>
      <td class="success">Fast</td>
      <td class="danger">Poor</td>
      <td class="success">Yes</td>
      <td class="danger">No</td>
      <td class="danger">No</td>
    </tr>
    <tr>
      <td>GAM</td>
      <td class="success">Yes</td>
      <td class="success">Fast</td>
      <td class="warning">Okay</td>
      <td class="success">Yes</td>
      <td class="danger">No</td>
      <td class="danger">No</td>
    </tr>
    <tr>
      <td>&nbsp;&nbsp;&nbsp;Prophet&nbsp;&nbsp;&nbsp;&nbsp;</td>
      <td class="warning">Partial</td>
      <td class="warning">Moderate</td>
      <td class="success">Good*</td>
      <td class="danger">No</td>
      <td class="danger">No</td>
      <td class="danger">No</td>
    </tr>
  </tbody>
</table>

### State space models
<table class="table">
  <thead>
    <tr>
      <th>Model</th>
      <th>Flexible</th>
      <th>Speed</th>
      <th>Accuracy</th>
      <th>Exogenous Regressors</th>
      <th>Dynamic Terms</th>
      <th>Evolving Terms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DSHW</td>
      <td class="danger">No</td>
      <td class="warning">Moderate</td>
      <td class="warning">Okay</td>
      <td class="danger">No</td>
      <td class="success">Yes</td>
      <td class="success">Yes</td>
    </tr>
    <tr>
      <td>BATS/TBATS</td>
      <td class="danger">No</td>
      <td class="danger">Slow*</td>
      <td class="success">Good*</td>
      <td class="danger">No</td>
      <td class="success">Yes</td>
      <td class="success">Yes</td>
    </tr>
    <tr>
      <td>MSARIMA</td>
      <td class="danger">No</td>
      <td class="danger">V. Slow</td>
      <td class="danger">Poor</td>
      <td class="success">Yes</td>
      <td class="success">Yes</td>
      <td class="success">Yes</td>
    </tr>
  </tbody>
</table>

.footnote[[*] This can depend on the data substantially]

---

# Proposed model

### A structural state space model, with:

- ### Multiple seasonality capabilities

- ### Flexible model specification

- ### Multiple sources of error

- ### Exogenous regressor support

- ### Handling of missing values

---
class: inverse, center, top

# Introducing...

.animated.zoomIn[.huge[
# FASSTER
]]

---
class: inverse, center, top

# Introducing...

.huge[
# FASSTER
]

.animated.slideInUp[
## .green.big[Forecasting] with .green.big[Additive] .green.big[Switching] of
## .green.big[Seasonality], .green.big[Trend] & .green.big[Exogenous] .green.big[Regressors]
]

---

# Switching Structure

FASSTER extends current state-space approaches by switching between states.

--

A DLM representation of a state-space model can be written as:
\begin{align*}
y_t &= F_t\theta_t + v_t, & v_t &\sim \mathcal{N}(0,V)\\
\theta_t &= G\theta_{t-1} + w_t, & w_t&\sim \mathcal{N}(0,W)
\end{align*}

--

Constructing this model to switch between two groups gives:
\begin{align*}
y_t &= \mathbf{I}_{t\in G_1}F_t\theta_{t}^{(1)} + \mathbf{I}_{t\in G_2}F_t\theta_{t}^{(2)} + v_t & v_t &\sim \mathcal{N}(0,V)
\end{align*}

Groups $G_1$ and $G_2$ define the switching rule (say weekdays and weekends).

--

<br>

In this model, the **state equations** for both groups follow the **same structure**.

The states have **different error terms** which produces **different behaviour**.

---

# Application to pedestrian traffic

This series contains a switching daily pattern over weekdays and weekends.
Each group can be modelled using level and hourly seasonal states.

```{r}
SthCross_fasster_tr <- pedestrian_cleaned$`Southern Cross Station` %>%
  filter(DateTime > ymd("2017-01-30") & DateTime <= ymd("2017-02-20"))
SthCross_fasster_fit <- SthCross_fasster_tr %>%
  fasster(Hourly_Counts ~ is_weekend(DateTime) %S% (poly(1) + trig(24)))

as.tibble(SthCross_fasster_tr) %>%
  ggplot(aes(x=DateTime, y=Hourly_Counts)) + 
  geom_line() + 
  ylab("Pedestrians counted") + 
  ggtitle("Pedestrian Traffic at Southern Cross Station") +
  xlab("Date")
```

---

An appropriate model can be constructed using switching states:

$$y_t = \mathbf{I}_{t\in Weekday}F_t\theta_{t}^{(Weekday)} + \mathbf{I}_{t\in Weekend}F_t\theta_{t}^{(Weekend)} + v_t$$

$$\text{Where}\hspace{1em}F_t\theta_t^{(i)} = \ell_{t}^{(i)} + f_{t}^{(i)} \hspace{1em}\text{and}\hspace{1em} v_t \sim \mathcal{N}(0,V)$$

--

```{r}
as.tibble(SthCross_fasster_tr) %>%
  rename(Actual = Hourly_Counts) %>%
  mutate(Fitted = SthCross_fasster_fit$fitted) %>%
  gather(Series, Values, Actual, Fitted) %>%
  ggplot(aes(x=DateTime, y=Values, colour=Series)) + 
  geom_line() + 
  ylab("Pedestrians counted") + 
  ggtitle("Pedestrian Traffic at Southern Cross Station") +
  xlab("Date")
```

---

## FASSTER allows flexible use of:

.pull-left[
- ### seasonal factors
- ### fourier seasonal terms
- ### n-th order polynomials
]
.pull-right[
- ### exogenous regressors
- ### ARMA processes
- ### state switching
]

???

So lets explore how these underlying states are built.
The equations are standard for DLMs and state-space models, so in the interest of time, these will be glossed over.

---

# seas(m): seasonal factors

This creates seasonal factors with frequency s.

Like other state space models (such as DSHW and BATS), seasonal factors are defined by rotating states.

For identification, the seasonal states set to sum to 0, reducing the required states by 1.

$$s_{1,t} = -\sum_{j=1}^m s_{j,t-1} + w_{1,t}, \hspace{1em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

$$s_{j,t} = s_{j-1, t-1} + w_{j,t}, \hspace{1em} w_{j,t} \sim \mathcal{N}(0,0) \hspace{1em}\forall j = 2, ..., m-1$$

---

# trig(m, q): seasonal fourier terms

This creates seasonal fourier terms with frequency s using q harmonics.
(Where $q \leq \lfloor s/2 \rfloor$)

As defined in TBATS, the underlying states for seasonal fourier terms are:

\begin{align*}
f_t &= \sum_{j=1}^{q} f_{j,t}\\
f_{j,t} &= f_{j,t-1}\cos \lambda_j + f_{j,t-1}^{*}\sin \lambda_j + \gamma_1d_t\\
f_{j,t}^{*} &= -f_{j,t-1}\sin \lambda_j + f_{j,t-1}^{*}\cos \lambda_j + \gamma_2d_t\\
\end{align*}

$$\text{Where }\lambda_j = \dfrac{2\pi j}{m}$$

Trigonometric seasonality is advantageous as it is:

- More flexible
- Reduces parameterisation problem
- Supports non-integer seasonal periods

???

This provides a more flexible specification of seasonality than seasonal factors, and reducing the number of harmonics can help speed up the model (with a trade off of smoother seasonality).

---

# poly(n): n-th order polynomials

This creates levels, trends, and higher order polynomial states

The state equation for a level $(\ell_t)$ in the model (poly(1)) is given by:
$$\ell_t = \ell_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

Extending this to include a trend state $(b_t)$ in the model (poly(2)) makes the state equations:

$$\ell_t = \ell_{t-1} + b_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$
$$b_t = b_{t-1} + w_{2,t}, \hspace{2em} w_{2,t} \sim \mathcal{N}(0,W_2)$$

In general, the $n^{th}$ order polynomial (poly(n)) is built with the states:
$$\theta_{j,t} = \theta_{j,t-1} + \theta_{j+1, t-1} + w_{j,t}, \hspace{1em} w_{j,t} \sim \mathcal{N}(0,W_j), \hspace{1em}\forall j=1,\ldots,n-1$$
$$\theta_{n,t} = \theta_{n,t-1} + w_{n,t}, \hspace{2em} w_{n,t} \sim \mathcal{N}(0,W_n)$$

---

# xreg: Exogenous regressors

Regression terms can be constructed by using a state to represent the regression coefficient for each regressor.
$$\beta_t = \beta_{t-1} + w_{1,t}, \hspace{2em} w_{1,t} \sim \mathcal{N}(0,W_1)$$

Then in the measurement equation, the coefficient for the state $\beta_t$ $(F_t)$ can be defined as the regressor itself $(x_t)$:

$$y_t = \beta_t x_t + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$
This has the benefit of allowing the regressor coefficient to evolve over time.

---

# ARMA(ar, ma): ARMA processes

Adding ARMA processes to state space models is a natural extension to correct remaining correlation structure in the residuals.

For ar $= (\phi_1, \ldots, \phi_p)$ and ma $= (\theta_1, \ldots, \theta_q)$, the appropriate states are given by:

\begin{align*}
\gamma_1,t &= \phi_1 \gamma_{1,t-1} + \gamma_{2, t-1} + \varepsilon_t\\
\gamma_j,t &= \phi_j \gamma_{1,t-1} + \gamma_{j+1, t-1} + \theta_{j-1} \varepsilon_t, & \forall j = 1, \ldots, r-1\\
\gamma_r,t &= \phi_r \gamma_{1,t-1} + \theta_{r-1} \varepsilon_t\\
\end{align*}

Where,
\begin{align*}
r &= max\{p, q+1\}\\
\phi_j &= 0, \hspace{1em}\forall j>r\\
\theta_j &= 0, \hspace{1em}\forall j>r-1\\
\varepsilon_t &\sim \mathcal{N}(0, \sigma^2)
\end{align*}

---

# %S%: State switching

The general measurement equation in a FASSTER model is:

$$y_t = F_t^{(0)}\theta_{t}^{(0)} + \sum_{j=1}^k\mathbf{I}_{t\in G_j}F_t^{(j)}\theta_{t}^{(j)} + v_t, \hspace{2em} v_t \sim \mathcal{N}(0,V)$$
Where $k$ is the number of switching combinations.

--

Note that:
- Each group can be built with a different model of states
- Groups can overlap, allowing complex state switching

--

.center.bold[This greatly enhances the flexibility of the model.]

---
class: inverse, center, top

# Model speed

--

## (It's not called FASSTER for nothing!)

---

# FASSTER and Dynamic Linear Models

A FASSTER model can be represented as a time-varying DLM.
This involves constructing the appropriate $F_t$ matrix to create the switching structure.

\begin{align*}
  y_t &= F_t\theta_t + v_t, & v_t&\sim \mathcal{N}(0,V)\\
  \theta_t &= G\theta_{t-1} + w_t, & w_t&\sim \mathcal{N}(0,W)\\
  \text{Where }\theta_0 &\sim \mathcal{N}(m_0, C_0)
\end{align*}

--

Therefore,

- State estimation can use the Kalman Filter
- Filtering, smoothing and forecasting can be done quickly*.

.footnote[[*] Relative to state-space models]

---

# Curse of dimensionality

Consider the model for pedestrian traffic seen earlier.
\begin{align*}
y_t &= \mathbf{I}_{t\in Weekday}F_t\theta_{t}^{(Weekday)} + \mathbf{I}_{t\in Weekend}F_t\theta_{t}^{(Weekend)} + v_t & v_t &\sim \mathcal{N}(0,V)\\
\end{align*}
$$\text{Where }F_t\theta_t^{(i)} = \ell_{t}^{(i)} + f_{t}^{(i)}$$

This model has 48 state equations (2 groups $\times$ (1 level + 23 fourier states)).

--

<hr>

The components that require estimation (bolded) are:
\begin{align*}
  y_t &= F_t\theta_t + v_t, & v_t&\sim \mathcal{N}(0,\mathbf{V})\\
  \theta_t &= G\theta_{t-1} + w_t, & w_t&\sim \mathcal{N}(0,\mathbf{W})\\
  \text{Where }\theta_0 &\sim \mathcal{N}(\mathbf{m_0}, \mathbf{C_0})
\end{align*}

There are well over 100 parameters that require estimation.

--

.center[Numerical optimisation techniques involving the .bold[MLE is infeasible]!]

???

If the model is built in the state-space framework... doesn't that mean it is slow?

(10 years of hourly data has 87,660 observations).
Computing the likelihood is slow due to the series length.

---

## Heuristic estimation (filterSmooth)

1. Filtering the data using the specified model with non-zero state variances

--

2. Obtain smoothed states $(\theta_t^{(s)} = \theta_t | \mathcal{D}_T)$ to approximate correct behaviour

--

3. The initial state parameters taken from the first smoothed state:
\begin{align*}
m_0 &= \mathbb{E}\left(\theta_0^{(s)}\right), & C_0 &= \text{Var}\left(\theta_0^{(s)}\right)
\end{align*}

--

4. Obtain state noise variances from the smoothed variance of $w_t$:
$$W = \text{Var}\left(w_t^{(s)}\right) = \text{Var}\left(\theta_t^{(s)} - G\theta_{t-1}^{(s)}\right)$$

--

5. Obtain measurement noise variance from smoothed variance of $v_t$:
$$V = \text{Var}\left(v_t^{(s)}\right) = \text{Var}\left(y_t - F_t\theta_t^{(s)}\right)$$

--

6. Repair restricted state variances for seasonal factors and ARMA terms

--

.center.bold[Only two passes through the data are required.]

---

class: inverse, center, top

# Implementation

.animated.zoomIn.sticker-math[
![fasster](resources/fasster.png)
]

---

class: inverse, center, top

# Implementation

.sticker-math[
![fasster](resources/fasster.png)
]

.sticker-math[
![dlm](resources/dlm.png)
![tidyverse](resources/tidyverse.png)
![forecast](resources/forecast.png)
]

???

Special note that since my last presentation, we have made a sticker for the forecast package!

---
class: inverse, top

.sticker-float[![fasster](resources/fasster.png)]
<br>
.center[
# The fasster package for R
]

<br>
<br>

The **development** version can be installed from GitHub using:

```{r, echo = TRUE, eval = FALSE}
# install.packages("devtools")
devtools::install_github("mitchelloharawild/fasster")
```

---

# Usage (Pedestrian Counts)
```{r}
SthCross_Ex <- SthCross_fasster_tr %>%
  mutate(DayType = ifelse(is_weekend(DateTime), "Weekend", "Weekday")) %>%
  select(DateTime, Hourly_Counts, DayType)
```

```{r, echo = TRUE, eval=FALSE}
SthCross_fasster_fit <- SthCross_Ex %>%
  fasster(Hourly_Counts ~ DayType %S% (poly(1) + trig(24)))
```

```{r}
SthCross_fasster_fit %>%
  ggfitted
```


---

# Usage (Electricity Demand)

```{r}
elecdemand_Ex <- elecdemand_plot %>%
  filter(DateTime < ymd("2014-02-01"))
```

```{r, echo=TRUE, eval=FALSE}
elecdemand_fasster_fit <- elecdemand_Ex %>%
  fasster(Demand ~ I((Temperature - mean(Temperature))^2) + 
                   WorkDay %S% (poly(1) + trig(48, 16)))
```

```{r}
elecdemand_fasster_fit <- elecdemand_Ex %>%
  fasster(Demand ~ I((Temperature - mean(Temperature))^2) + 
                   WorkDay %S% (poly(1) + trig(48, 16)))
elecdemand_fasster_fit %>% 
  ggfitted
```

---

.sticker-float[![dlm](resources/dlm.png)]
<br>
# Built on top of dlm

The **dlm** package is the backbone for the **fasster** package.

--

It provides necessary tools including:

- DLM object structure
- Kalman filter
- Kalman smoother
- Model building functions

--

It does not provide:

- Time-varying forecasts
- Plotting tools

---

.sticker-float[![tidyverse](resources/tidyverse.png)]
<br>
# Consistent with tidyverse API


**fasster**  complements with the **tidyverse** of packages.

<br>
<br>

.center[
![r4ds_workflow](resources/r4ds_workflow.png)

R for Data Science: suggested project workflow
]

---

.sticker-float[![forecast](resources/forecast.png)]
<br>
# Extends the forecast package

**fasster** objects are consistent with the **forecast** package.

--

Which provides:

- Plotting of forecasts and components
- Model extraction methods
- Accuracy measures
- Residual diagnostics.

---

# Example workflow

The way **fasster** integrates with other package is clear in this example of forecasting half-hourly electricity demand (from Taylor, 2003).

```{r, echo=TRUE, eval=FALSE}
library(fasster)
library(tidyverse)
library(lubridate)
library(forecast)

tbl_taylor <- tibble(taylor) %>%
  mutate(DateTime = seq(ymd_h("2000-6-5 00"), by="30 mins", length.out=length(taylor)),
         DayType = ifelse(wday(DateTime) %in% 2:6, "Weekday", "Weekend")) %>% 
  filter(month(DateTime) == 8)
tbl_taylor %>%
  filter(DateTime < ymd("2000-8-21")) %>%
  fasster(taylor ~ DayType %S% (poly(1) + trig(48, 16))) %>%
  forecast(newdata=tbl_taylor %>%
             filter(DateTime >= ymd("2000-8-21"))) %>%
  autoplot() + 
  ylab("Electricity Demand (Megawatts)") + 
  xlab("Time (5 June 2000 - 27 August 2000)")
```

---

# Example workflow

```{r}
library(fasster)
library(tidyverse)
library(lubridate)
library(forecast)

tbl_taylor <- tibble(taylor) %>%
  mutate(DateTime = seq(ymd_h("2000-6-5 00"), by="30 mins", length.out=length(taylor)),
         DayType = ifelse(wday(DateTime) %in% 2:6, "Weekday", "Weekend")) %>% 
  filter(month(DateTime) == 8)
tbl_taylor %>%
  filter(DateTime < ymd("2000-8-21")) %>%
  fasster(taylor ~ DayType %S% (poly(1) + trig(48, 16))) %>%
  forecast(newdata=tbl_taylor %>%
             filter(DateTime >= ymd("2000-8-21"))) %>%
  autoplot() + 
  ylab("Electricity Demand (Megawatts)") + 
  xlab("Time (5 June 2000 - 27 August 2000)")
```

---

# Model specification

The formula model specification for **fasster** is designed to be:

.pull-left[
- Concise
- Convenient
- Intuitive
]
.pull-right[
- Unsurprising
- Unrestricted
- Flexible
]

--

<br>

Standard model formula rules are conserved.

```{r, echo=TRUE, eval=FALSE}
data %>% fasster(y ~ x1 + log(x2) + x1:x2)
```

Specifying complex structures is convenient.

```{r, echo=TRUE, eval=FALSE}
data %>% fasster(y ~ poly(1) + trig(24))
```

---

# Model specification

Switching functions intuitively

```{r, echo=TRUE, eval=FALSE}
data %>% fasster(y ~ groupVar %S% (poly(1) + trig(24)))
```

Exogenous regressors are easy to include

```{r, echo=TRUE, eval=FALSE}
data %>% fasster(y ~ x1 + groupVar %S% (poly(1) + trig(24)))
```

Complex models are simple to specify

```{r, echo=TRUE, eval=FALSE}
data %>% fasster(y ~ x1 + gV1 %S% (gV2 %S% poly(1) + trig(24)))
```


---
class: inverse, center, top

# Applications and results

---

# Extensions

- Automatic detection of groups / model
- More flexible within-group model specification
- Streaming data
- Improved heuristic estimation

---
class: inverse, center, top

# Questions?
